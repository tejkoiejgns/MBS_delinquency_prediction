{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf2yJu0i20Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ae8eaa-37ef-4a9d-ccec-8a489450e960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/My Drive/new_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gklvGVGCAMw"
      },
      "outputs": [],
      "source": [
        "X = df.drop('EverDelinquent', axis=1)\n",
        "y = df['EverDelinquent'].values\n",
        "\n",
        "smt = SMOTE()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_sm,y_train_sm = smt.fit_resample(X_train,y_train)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEn5G_yI2MAg"
      },
      "source": [
        "## Logistic Regression - Chenqi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##before rebalancing\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "report= classification_report(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4BGoneg84df",
        "outputId": "2ace1f57-2d23-42ee-ffcd-91ee25707301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.26%\n",
            "Confusion Matrix:\n",
            "[[30546    55]\n",
            " [10013    76]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      1.00      0.86     30601\n",
            "         1.0       0.58      0.01      0.01     10089\n",
            "\n",
            "    accuracy                           0.75     40690\n",
            "   macro avg       0.67      0.50      0.44     40690\n",
            "weighted avg       0.71      0.75      0.65     40690\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjzkFj1B2Kti"
      },
      "outputs": [],
      "source": [
        "## after\n",
        "model_balanced = LogisticRegression(class_weight='balanced')\n",
        "model_balanced.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_balanced = model_balanced.predict(X_test_scaled)\n",
        "\n",
        "accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
        "conf_matrix_balanced = confusion_matrix(y_test, y_pred_balanced)\n",
        "report_balanced = classification_report(y_test, y_pred_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbZ_vJ3L2XYK",
        "outputId": "04593327-9b10-4b3b-d005-52f3316f160d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.29%\n",
            "Confusion Matrix:\n",
            "[[18265 12336]\n",
            " [ 3824  6265]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.60      0.69     30601\n",
            "         1.0       0.34      0.62      0.44     10089\n",
            "\n",
            "    accuracy                           0.60     40690\n",
            "   macro avg       0.58      0.61      0.57     40690\n",
            "weighted avg       0.71      0.60      0.63     40690\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_balanced * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_balanced)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU1FvaoV2RE2"
      },
      "source": [
        "# SVM - Leyi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ5b8p5O2TZV",
        "outputId": "92397390-9c41-4e16-dccc-4ce72111b0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training score = 0.7526726562253141\n",
            "Testing score = 0.7520275251904645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model=LinearSVC()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "train_pred_svc=model.predict(X_train_scaled)\n",
        "y_preds_svc=model.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Training score = {metrics.accuracy_score(y_train,train_pred_svc)}\")\n",
        "print(f\"Testing score = {metrics.accuracy_score(y_test,y_preds_svc)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy_svc = accuracy_score(y_train,train_pred_svc)*100\n",
        "print('training data accuracy is:', training_accuracy_svc)\n",
        "print()\n",
        "\n",
        "clf_report_svc = classification_report(y_train,train_pred_svc)\n",
        "print('Classification report:\\n', clf_report_svc)\n",
        "print()\n",
        "\n",
        "confusion_matrix(y_train,train_pred_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzJfuJM-Hgc",
        "outputId": "2d9ea5b5-0d27-4363-dfb8-d211a3a3cd57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data accuracy is: 75.26831888606849\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      1.00      0.86     71461\n",
            "         1.0       0.53      0.00      0.00     23482\n",
            "\n",
            "    accuracy                           0.75     94943\n",
            "   macro avg       0.64      0.50      0.43     94943\n",
            "weighted avg       0.70      0.75      0.65     94943\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[71454,     7],\n",
              "       [23474,     8]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_accuracy_svc = accuracy_score(y_test,y_preds_svc)*100\n",
        "print('training data accuracy is:', testing_accuracy_svc)\n",
        "print()\n",
        "\n",
        "clf_report_svc = classification_report(y_test,y_preds_svc)\n",
        "print('Classification report:\\n', clf_report_svc)\n",
        "print()\n",
        "\n",
        "confusion_matrix(y_test,y_preds_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysKFFb5SSY-d",
        "outputId": "59b29467-6cfc-44a9-8bb8-cd02e4453fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data accuracy is: 75.20275251904644\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      1.00      0.86     30601\n",
            "         1.0       0.33      0.00      0.00     10089\n",
            "\n",
            "    accuracy                           0.75     40690\n",
            "   macro avg       0.54      0.50      0.43     40690\n",
            "weighted avg       0.65      0.75      0.65     40690\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30599,     2],\n",
              "       [10088,     1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcbRA1XqHqCh"
      },
      "source": [
        "# LGBM - Leyi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH7Gip1kEvnH",
        "outputId": "1bbb2baa-9fb9-4695-ad39-e92ff9ecd97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Info] Number of positive: 23482, number of negative: 71461\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022905 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 408\n",
            "[LightGBM] [Info] Number of data points in the train set: 94943, number of used features: 6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247327 -> initscore=-1.112918\n",
            "[LightGBM] [Info] Start training from score -1.112918\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'num_leaves': 15,\n",
        "    'max_depth': 4,\n",
        "    'min_data_in_leaf': 20\n",
        "}\n",
        "lgbm_model = lgb.LGBMClassifier(**params)\n",
        "lgbm_model.fit(X_train_scaled, y_train)\n",
        "train_pred_lgbm = lgbm_model.predict(X_train_scaled)\n",
        "test_pred_lgbm = lgbm_model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_accuracy_lgbm = accuracy_score(y_test,test_pred_lgbm)*100\n",
        "print('training data accuracy is:', testing_accuracy_lgbm)\n",
        "print()\n",
        "\n",
        "clf_report_lgbm = classification_report(y_test,test_pred_lgbm)\n",
        "print('Classification report:\\n', clf_report_lgbm)\n",
        "print()\n",
        "\n",
        "confusion_matrix(y_test,test_pred_lgbm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMpu68lgSr6G",
        "outputId": "1c494faa-5c78-4249-d1e6-83467427d9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data accuracy is: 75.23470140083559\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.99      0.86     30601\n",
            "         1.0       0.51      0.02      0.04     10089\n",
            "\n",
            "    accuracy                           0.75     40690\n",
            "   macro avg       0.63      0.51      0.45     40690\n",
            "weighted avg       0.70      0.75      0.66     40690\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30377,   224],\n",
              "       [ 9853,   236]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy_lgbm = accuracy_score(y_train,train_pred_lgbm)*100\n",
        "print('training data accuracy is:', training_accuracy_lgbm)\n",
        "print()\n",
        "\n",
        "clf_report_lgbm = classification_report(y_train,train_pred_lgbm)\n",
        "print('Classification report:\\n', clf_report_lgbm)\n",
        "print()\n",
        "\n",
        "confusion_matrix(y_train,train_pred_lgbm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZDZRxya_S9y",
        "outputId": "531cc808-2dad-485a-cc65-67cbc8906858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data accuracy is: 75.47686506640827\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.99      0.86     71461\n",
            "         1.0       0.60      0.03      0.05     23482\n",
            "\n",
            "    accuracy                           0.75     94943\n",
            "   macro avg       0.68      0.51      0.45     94943\n",
            "weighted avg       0.72      0.75      0.66     94943\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[71048,   413],\n",
              "       [22870,   612]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfdTrjH_2Lhu"
      },
      "source": [
        "# Neural Network - Hsuan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Not scaled and rebalanced:**"
      ],
      "metadata": {
        "id": "bCCsBBjiwho1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgVCmQLfY-b_"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(6,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQGnVMGDbKlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce40c38-c3c3-48c3-89a8-9086af1deb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1272/1272 [==============================] - 3s 2ms/step - loss: 0.5601 - accuracy: 0.7521\n",
            "1272/1272 [==============================] - 2s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
        "model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Only scaled:**"
      ],
      "metadata": {
        "id": "KTnIK8l0hcug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100, batch_size=16, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAJhZbt1gHzK",
        "outputId": "5ebc3aef-0f86-4978-e0d8-ad4706f49284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d13ee726c20>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Evaluation Loss:\", evaluation[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation[1])\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_binary = (y_pred > 0.5)\n",
        "\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_train_pred_binary = (y_train_pred > 0.5)\n",
        "\n",
        "training_accuracy_nn = accuracy_score(y_train, y_train_pred_binary) * 100\n",
        "print('Training data accuracy is:', training_accuracy_nn)\n",
        "print()\n",
        "\n",
        "clf_report_nn = classification_report(y_test, y_pred_binary)\n",
        "print('Classification report:\\n', clf_report_nn)\n",
        "print()\n",
        "\n",
        "confusion_matrix_nn = confusion_matrix(y_test, y_pred_binary)\n",
        "print('Confusion Matrix:\\n', confusion_matrix_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxm2dEuchQhf",
        "outputId": "8d6d068a-67a5-43d7-956d-f7b83a65d645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1272/1272 [==============================] - 5s 4ms/step - loss: 0.5356 - accuracy: 0.7522\n",
            "Evaluation Loss: 0.5355596542358398\n",
            "Evaluation Accuracy: 0.7521504163742065\n",
            "1272/1272 [==============================] - 4s 3ms/step\n",
            "2967/2967 [==============================] - 6s 2ms/step\n",
            "Training data accuracy is: 75.33256796182974\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.99      0.86     30601\n",
            "         1.0       0.50      0.03      0.05     10089\n",
            "\n",
            "    accuracy                           0.75     40690\n",
            "   macro avg       0.63      0.51      0.45     40690\n",
            "weighted avg       0.69      0.75      0.66     40690\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[30346   255]\n",
            " [ 9830   259]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaled and rebalanced:**\n"
      ],
      "metadata": {
        "id": "Qeq4D1jvpv9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smt = SMOTE()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_scaled, y_train_sm, epochs=100, batch_size=16, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuRkwcqOpwLJ",
        "outputId": "ba060a5a-d6b9-43ed-d911-3fab44a12c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d13ffea2890>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Evaluation Loss:\", evaluation[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation[1])\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_binary = (y_pred > 0.5)\n",
        "\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_train_pred_binary = (y_train_pred > 0.5)\n",
        "\n",
        "training_accuracy_nn = accuracy_score(y_train_sm, y_train_pred_binary) * 100\n",
        "print('Training data accuracy is:', training_accuracy_nn)\n",
        "print()\n",
        "\n",
        "clf_report_nn = classification_report(y_test, y_pred_binary)\n",
        "print('Classification report:\\n', clf_report_nn)\n",
        "print()\n",
        "\n",
        "confusion_matrix_nn = confusion_matrix(y_test, y_pred_binary)\n",
        "print('Confusion Matrix:\\n', confusion_matrix_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3dc3LPKpwN_",
        "outputId": "abb30164-e538-4abc-84b2-9b2d0cfff802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1272/1272 [==============================] - 2s 2ms/step - loss: 0.6638 - accuracy: 0.5945\n",
            "Evaluation Loss: 0.663750171661377\n",
            "Evaluation Accuracy: 0.5945441126823425\n",
            "1272/1272 [==============================] - 3s 2ms/step\n",
            "4467/4467 [==============================] - 7s 2ms/step\n",
            "Training data accuracy is: 66.12557898713985\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.59      0.69     30601\n",
            "         1.0       0.33      0.61      0.43     10089\n",
            "\n",
            "    accuracy                           0.59     40690\n",
            "   macro avg       0.57      0.60      0.56     40690\n",
            "weighted avg       0.70      0.59      0.62     40690\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[18051 12550]\n",
            " [ 3948  6141]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFYGZ8yRVuR"
      },
      "source": [
        "# Random Forest - Sike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x-E0qiXRcEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78205025-9127-4f29-f724-8ae977d1b24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For base model:\n",
            "The accuracy score is 0.6940525927746375\n",
            "The F1 score is 0.2542383034805008\n",
            "The auc is 0.5319311391580198\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "prediction = rf.predict(X_test_scaled)\n",
        "print(\"For base model:\")\n",
        "print(\"The accuracy score is\" , accuracy_score(y_test, prediction))\n",
        "print(\"The F1 score is\" , f1_score(y_test,prediction))\n",
        "print(\"The auc is\",roc_auc_score(y_test,prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V8lxfqQVe4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "15fa8bfe-be64-43bd-8b86-4913484e12d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-a33a926ab151>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_sm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For base and oversampling model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The accuracy score is\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smt = SMOTE()\n",
        "X_train_sm,y_train_sm = smt.fit_resample(X_train,y_train)\n",
        "rf.fit(X_train_sm,y_train_sm)\n",
        "prediction = rf.predict(X_val)\n",
        "print(\"For base and oversampling model:\")\n",
        "print(\"The accuracy score is\" , accuracy_score(y_val, prediction))\n",
        "# Display F1 score\n",
        "print(\"The F1 score is\" , f1_score(y_val,prediction))\n",
        "# Displat auc score\n",
        "print(\"The auc is\",roc_auc_score(y_val,prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuQLoarcViot"
      },
      "source": [
        "After Dealing with the imbalanced, f1 and auc increase while accuracy score decreasse. Because of regarding predict accuracy as the most important, decide not do the oversampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSnEYULpWBTv"
      },
      "outputs": [],
      "source": [
        "#tune parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.warn('ignore')\n",
        "rf1 = RandomForestClassifier()\n",
        "params = {'n_estimators':[200,400,600,800],\n",
        "          'max_features':['sqrt', 'log2', \"auto\", 10]}\n",
        "gsv_rf = GridSearchCV(rf1, params, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "gsv_rf.fit(X_train_scaled,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AubOJwLSLM7W"
      },
      "outputs": [],
      "source": [
        "gsv_rf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sKG91DtLPrf"
      },
      "source": [
        "{'max_features': 'log2', 'n_estimators': 800}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvNfhLa-LSNS"
      },
      "outputs": [],
      "source": [
        "prediction_rf = RandomForestClassifier(max_features='log2',n_estimators=800,random_state=1).fit(X_train_scaled,y_train).predict(X_test_scaled)\n",
        "#\n",
        "# Display accuracy score\n",
        "print(\"The accuracy score is\" , accuracy_score(y_test, prediction_rf))\n",
        "# Display F1 score\n",
        "print(\"The F1 score is\" , f1_score(y_test,prediction_rf))\n",
        "# Displat auc score\n",
        "print(\"The auc is\",roc_auc_score(y_test,prediction_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjpSh_DsLXXJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,prediction_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf5R8ULALoCa"
      },
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.77      0.86      0.81     30601\n",
        "         1.0       0.32      0.21      0.25     10089\n",
        "\n",
        "    accuracy                           0.70     40690\n",
        "    macro avg      0.55      0.53      0.53     40690\n",
        "    weighted avg   0.66      0.70      0.67     40690"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6daDEA6L6TP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test,prediction_rf)\n",
        "#create ROC curve\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(roc_auc_score(y_test, prediction_rf)))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.title(\"ROC curve for random forest\")\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}